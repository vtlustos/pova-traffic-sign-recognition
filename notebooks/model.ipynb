{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_YOLO = False\n",
    "TRAIN_DETR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 training\n",
    "This part of the project explores capabilites of the YOLOv8 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLE_STEP = False\n",
    "BASE_PATH = \"C:/Users/tlust/Downloads/mtsd/yolov8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_path = os.path.join(BASE_PATH, \"detect\", \"dataset.yaml\")\n",
    "classify_path = os.path.join(BASE_PATH, \"classify\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-step fully taxonomy detection + classification to 313 classes\n",
    "Initial experiment to assess the model's default performance across the entire taxonomy. Anticipated to yield suboptimal results due to the extensive number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_YOLO and DOUBLE_STEP == False:\n",
    "    model = YOLO(\"yolov8m.pt\")  # load a pretrained model\n",
    "    results = model.train(data=detect_path, epochs=100, imgsz=640, batch=16, fliplr=0)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-stage pipeline\n",
    "Anticipated to yield improved outcomes as a result of decoupling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. train binary sign detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_YOLO and DOUBLE_STEP:\n",
    "    model = YOLO('yolov8n.pt')  # load a pretrained model\n",
    "    results = model.train(data=detect_path, epochs=10, imgsz=640)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. train sign classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_YOLO and DOUBLE_STEP:\n",
    "    model = YOLO('yolov8x-cls.pt')  # load a pretrained model\n",
    "    results = model.train(data=classify_path, epochs=100, imgsz=224, batch=128)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/tlust/Downloads/mtsd/coco'\n",
    "NUM_CLASSES = 235\n",
    "BATCH_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from transformers import DetrImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import DetrForObjectDetection\n",
    "from pytorch_lightning import Trainer\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappilaryDataset(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, dir, processor, train=True):\n",
    "        super(MappilaryDataset, self).__init__(\n",
    "            os.path.join(dir, \"images\"),\n",
    "            os.path.join(dir, \"annotations\", \"train.json\" if train else \"val.json\")\n",
    "        )\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(MappilaryDataset, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {\n",
    "            'image_id': image_id, \n",
    "            'annotations': target\n",
    "        }\n",
    "        encoding = self.processor(\n",
    "            images=img, \n",
    "            annotations=target, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "        return pixel_values, target\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        pixel_values = [item[0] for item in batch]\n",
    "        encoding = self.processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "        labels = [item[1] for item in batch]\n",
    "        batch = {}\n",
    "        batch['pixel_values'] = encoding['pixel_values']\n",
    "        batch['pixel_mask'] = encoding['pixel_mask']\n",
    "        batch['labels'] = labels\n",
    "        return batch  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detr(pl.LightningModule):\n",
    "   def __init__(self, lr, lr_backbone, weight_decay, train_dl, val_dl):\n",
    "      super().__init__()\n",
    "      self.model = DetrForObjectDetection.from_pretrained(\n",
    "         \"facebook/detr-resnet-50\",\n",
    "         num_labels=NUM_CLASSES,\n",
    "         ignore_mismatched_sizes=True\n",
    "      )\n",
    "      self.lr = lr\n",
    "      self.lr_backbone = lr_backbone\n",
    "      self.weight_decay = weight_decay\n",
    "      self.train_dl = train_dl\n",
    "      self.val_dl = val_dl\n",
    "      self.map = MeanAveragePrecision()\n",
    "\n",
    "   def forward(self, pixel_values, pixel_mask):\n",
    "      outputs = self.model(\n",
    "         pixel_values=pixel_values, \n",
    "         pixel_mask=pixel_mask\n",
    "      )\n",
    "      return outputs   \n",
    "   \n",
    "   def training_step(self, batch, batch_idx):\n",
    "      # 1: forward pass\n",
    "      outputs = self.model(\n",
    "         pixel_values=batch[\"pixel_values\"], \n",
    "         pixel_mask=batch[\"pixel_mask\"],\n",
    "         labels=[\n",
    "            {k: v.to(self.device) for k, v in t.items()} \n",
    "            for t in batch[\"labels\"]\n",
    "         ]\n",
    "      )\n",
    "\n",
    "      # 2: log loss\n",
    "      self.log(\"train_loss\", outputs.loss)\n",
    "      for k,v in outputs.loss_dict.items():\n",
    "         self.log(\"train_\" + k, v.item())\n",
    "\n",
    "      # 3: backpropagation\n",
    "      return outputs.loss\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "      # 1: forward pass\n",
    "      outputs = self.model(\n",
    "         pixel_values=batch[\"pixel_values\"], \n",
    "         pixel_mask=batch[\"pixel_mask\"],\n",
    "         labels=[\n",
    "            {k: v.to(self.device) for k, v in t.items()} \n",
    "            for t in batch[\"labels\"]\n",
    "         ]\n",
    "      )\n",
    "\n",
    "      # 2: log loss\n",
    "      self.log(\"val_loss\", outputs.loss)\n",
    "      for k,v in outputs.loss_dict.items():\n",
    "         self.log(\"val_\" + k, v.item())\n",
    "\n",
    "      # 3: compute mAP\n",
    "      preds = [\n",
    "         {\n",
    "            \"boxes\": outputs[\"pred_boxes\"][i],\n",
    "            \"scores\": torch.softmax(outputs[\"logits\"][i], -1).max(-1).values,\n",
    "            \"labels\": torch.softmax(outputs[\"logits\"][i], -1).max(-1).indices\n",
    "         } for i in range(len(outputs[\"pred_boxes\"]))\n",
    "      ]\n",
    "      targets = [\n",
    "         {\n",
    "            \"boxes\": label[\"boxes\"],\n",
    "            \"labels\": label[\"class_labels\"]\n",
    "         } \n",
    "         for label in batch[\"labels\"]\n",
    "      ]\n",
    "      self.map.update(preds, targets)\n",
    "   \n",
    "   def on_validation_epoch_end(self):\n",
    "      self.log('val_mAP',self.map.compute()['map'], prog_bar=True)\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "      param_dicts = [\n",
    "            {\n",
    "               \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]\n",
    "            },\n",
    "            {\n",
    "               \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "               \"lr\": self.lr_backbone,\n",
    "            }\n",
    "      ]\n",
    "      optimizer = torch.optim.AdamW(\n",
    "         param_dicts, \n",
    "         lr=self.lr,\n",
    "         weight_decay=self.weight_decay\n",
    "      )\n",
    "      return optimizer \n",
    "   \n",
    "   def train_dataloader(self):\n",
    "      return self.train_dl\n",
    "   \n",
    "   def val_dataloader(self):\n",
    "      return self.val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_DETR:\n",
    "  processor = DetrImageProcessor.from_pretrained(\n",
    "      \"facebook/detr-resnet-50\"\n",
    "  )\n",
    "\n",
    "  # 1: load dataset\n",
    "  train_dataset = MappilaryDataset(\n",
    "      dir=PATH, \n",
    "      processor=processor\n",
    "  )\n",
    "  val_dataset = MappilaryDataset(\n",
    "      dir=PATH, \n",
    "      processor=processor, train=False\n",
    "  )\n",
    "  train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    "  )\n",
    "  val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    batch_size=BATCH_SIZE\n",
    "  )\n",
    "\n",
    "  # 2: init model\n",
    "  model = Detr(\n",
    "    lr=1e-4, \n",
    "    lr_backbone=1e-5,\n",
    "    weight_decay=1e-4, \n",
    "    train_dl=train_dataloader, \n",
    "    val_dl=val_dataloader\n",
    "  )\n",
    "\n",
    "  # 3: fine-tune\n",
    "  trainer = Trainer(\n",
    "      devices=1, \n",
    "      accelerator=\"gpu\",\n",
    "      max_epochs=10, \n",
    "      gradient_clip_val=0.1, \n",
    "      accumulate_grad_batches=(32 // BATCH_SIZE), \n",
    "      log_every_n_steps=1\n",
    "  )\n",
    "  trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
